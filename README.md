# GPT-2

(WIP) A pure Python implementation of inference in GPT-2, with no external dependencies[^1] (except for testing).

There are many like it, but this one is mine.

[^1]: Currently uses `regex` for word splitting in tokenization.

## Checklist

- [x] Tokenizer
- [ ] Model
- [ ] Inference

## Useful resources

- [GPT in 60 lines of NumPy, Jay Mody](https://jaykmody.com/blog/gpt-from-scratch/)
- [Byte Pair Encoding tokenization, Hugging Face](https://huggingface.co/learn/llm-course/en/chapter6/5#implementing-bpe)